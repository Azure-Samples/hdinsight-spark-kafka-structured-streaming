{"nbformat_minor": 2, "cells": [{"source": "## To use this notebook\n\nJupyter Notebooks allow you to modify and run the code in this document. To run a section (known as a 'cell',) select it and then use CTRL + ENTER, or select the play button on the toolbar above. Note that each section already has some example output beneath it, so you can see what the results of running a cell will look like.\n\nNOTE: You must run each cell in order, from top to bottom. Running cells out of order can result in an error.\n\n## Requirements\n\n* An Azure Virtual Network\n* A Spark on HDInsight 3.6 cluster, inside the virtual network\n* A Kafka on HDInsight cluster, inside the virtual network\n\n## Load packages\n\nTo use Spark structured streaming with Kafka, you must load the spark-sql-kafka package. The version must match the version of both kafka and Spark that you are using. The name of the package contains the versions that it works with. For example, `spark-sql-kafka-0-10_2.11:2.1.0` works with the following versions:\n\n* Kafka 0.10\n* Spark 2.1.0\n* Scala 2.11\n\nRun the next cell to load a package that works with Kafka on HDInsight 3.6, and Spark 2.1 on HDInsight 3.6.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "source": "%%configure -f\n{\n    \"conf\": {\n        \"spark.jars.packages\": \"org.apache.spark:spark-sql-kafka-0-10_2.11:2.1.0\", \n        \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.11\"\n    }\n}\n", "outputs": [{"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "Current session configs: <tt>{u'kind': 'spark', u'conf': {u'spark.jars.packages': u'org.apache.spark:spark-sql-kafka-0-10_2.11:2.1.0', u'spark.jars.excludes': u'org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.11'}}</tt><br>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>6</td><td>application_1497636509341_0006</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-spark.0cq2uian340ujell3vitepslnh.jx.internal.cloudapp.net:8088/proxy/application_1497636509341_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.13:30060/node/containerlogs/container_1497636509341_0006_01_000001/livy\">Link</a></td><td></td></tr></table>"}, "metadata": {}}], "metadata": {"collapsed": false}}, {"source": "## Define a schema for the data\nWhen reading data from Kafka, the data is provided in the 'value' column. In this example, the data is a JSON document that describes a Tweet. Run the following cell to create a schema for the JSON document structure.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 2, "cell_type": "code", "source": "// Import bits useed for declaring schemas and working with JSON data\nimport org.apache.spark.sql._\nimport org.apache.spark.sql.types._\nimport org.apache.spark.sql.functions._\n\n// Define the structure of the Twitter JSON document that is read from Kafka\n// Note, this isn't pretty, but there's some odd behavior where moving .add to \n// a new line causes an error.\nval schema = (new StructType).add(\"created_at\", StringType).add(\"id\", LongType).add(\"id_str\", StringType).add(\"text\", StringType).add(\"source\", StringType).add(\"truncated\", BooleanType).add(\"in_reply_to_status_id\", LongType).add(\"in_reply_to_status_id_str\", StringType).add(\"in_reply_to_user_id\", LongType).add(\"in_reply_to_user_id_str\", StringType).add(\"in_reply_to_screen_name\", StringType).add(\"user\", (new StructType).add(\"id\", LongType)\n        .add(\"id_str\", StringType)\n        .add(\"name\", StringType)\n        .add(\"screen_name\", StringType)\n        .add(\"location\", StringType)\n        .add(\"url\", StringType)\n        .add(\"description\", StringType)\n        .add(\"protected\", BooleanType)\n        .add(\"verified\", BooleanType)\n        .add(\"followers_count\", LongType)\n        .add(\"friends_count\", LongType)\n        .add(\"listed_count\", LongType)\n        .add(\"favourites_count\", LongType)\n        .add(\"statuses_count\", LongType)\n        .add(\"created_at\", StringType)\n        .add(\"utc_offset\", IntegerType)\n        .add(\"time_zone\", StringType)\n        .add(\"geo_enabled\", BooleanType)\n        .add(\"lang\", StringType)\n        .add(\"contributors_enabled\", BooleanType)\n        .add(\"is_translator\", BooleanType)\n        .add(\"profile_background_color\", StringType)\n        .add(\"profile_background_image_url\", StringType)\n        .add(\"profile_background_image_url_https\", StringType)\n        .add(\"profile_background_tile\", BooleanType)\n        .add(\"profile_link_color\", StringType)\n        .add(\"profile_sidebar_border_color\", StringType)\n        .add(\"profile_sidebar_fill_color\", StringType)\n        .add(\"profile_text_color\", StringType)\n        .add(\"profile_use_background_image\", BooleanType)\n        .add(\"profile_image_url\", StringType)\n        .add(\"profile_image_url_https\", StringType)\n        .add(\"profile_banner_url\", StringType)\n        .add(\"default_profile\", BooleanType)\n        .add(\"default_profile_image\", BooleanType)\n        .add(\"following\", StringType)\n        .add(\"follow_request_sent\", StringType)\n        .add(\"notifications\", StringType)).add(\"geo\", StringType).add(\"coordinates\", StringType).add(\"place\", StringType).add(\"contributors\", StringType).add(\"is_quote_status\", BooleanType).add(\"retweet_count\", LongType).add(\"favorite_count\", LongType).add(\"entities\", (new StructType)\n        .add(\"hashtags\", ArrayType((new StructType)\n            .add(\"text\", StringType)\n            .add(\"indices\", ArrayType(LongType)))).add(\"urls\", ArrayType((new StructType)\n            .add(\"url\", StringType)\n            .add(\"expanded_url\", StringType)\n            .add(\"display_url\", StringType)\n            .add(\"indices\", ArrayType(LongType))))\n        .add(\"user_mentions\", ArrayType(StringType))\n        .add(\"symbols\", ArrayType(StringType))).add(\"favorited\", BooleanType).add(\"retweeted\", BooleanType).add(\"possibly_sensitive\", BooleanType).add(\"filter_level\", StringType).add(\"lang\", StringType).add(\"timestamp_ms\", StringType)\n\n// Display a tree view of the schema.\nschema.printTreeString", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7</td><td>application_1497636509341_0007</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-spark.0cq2uian340ujell3vitepslnh.jx.internal.cloudapp.net:8088/proxy/application_1497636509341_0007/\">Link</a></td><td><a target=\"_blank\" href=\"http://10.0.0.12:30060/node/containerlogs/container_1497636509341_0007_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\nroot\n |-- created_at: string (nullable = true)\n |-- id: long (nullable = true)\n |-- id_str: string (nullable = true)\n |-- text: string (nullable = true)\n |-- source: string (nullable = true)\n |-- truncated: boolean (nullable = true)\n |-- in_reply_to_status_id: long (nullable = true)\n |-- in_reply_to_status_id_str: string (nullable = true)\n |-- in_reply_to_user_id: long (nullable = true)\n |-- in_reply_to_user_id_str: string (nullable = true)\n |-- in_reply_to_screen_name: string (nullable = true)\n |-- user: struct (nullable = true)\n |    |-- id: long (nullable = true)\n |    |-- id_str: string (nullable = true)\n |    |-- name: string (nullable = true)\n |    |-- screen_name: string (nullable = true)\n |    |-- location: string (nullable = true)\n |    |-- url: string (nullable = true)\n |    |-- description: string (nullable = true)\n |    |-- protected: boolean (nullable = true)\n |    |-- verified: boolean (nullable = true)\n |    |-- followers_count: long (nullable = true)\n |    |-- friends_count: long (nullable = true)\n |    |-- listed_count: long (nullable = true)\n |    |-- favourites_count: long (nullable = true)\n |    |-- statuses_count: long (nullable = true)\n |    |-- created_at: string (nullable = true)\n |    |-- utc_offset: integer (nullable = true)\n |    |-- time_zone: string (nullable = true)\n |    |-- geo_enabled: boolean (nullable = true)\n |    |-- lang: string (nullable = true)\n |    |-- contributors_enabled: boolean (nullable = true)\n |    |-- is_translator: boolean (nullable = true)\n |    |-- profile_background_color: string (nullable = true)\n |    |-- profile_background_image_url: string (nullable = true)\n |    |-- profile_background_image_url_https: string (nullable = true)\n |    |-- profile_background_tile: boolean (nullable = true)\n |    |-- profile_link_color: string (nullable = true)\n |    |-- profile_sidebar_border_color: string (nullable = true)\n |    |-- profile_sidebar_fill_color: string (nullable = true)\n |    |-- profile_text_color: string (nullable = true)\n |    |-- profile_use_background_image: boolean (nullable = true)\n |    |-- profile_image_url: string (nullable = true)\n |    |-- profile_image_url_https: string (nullable = true)\n |    |-- profile_banner_url: string (nullable = true)\n |    |-- default_profile: boolean (nullable = true)\n |    |-- default_profile_image: boolean (nullable = true)\n |    |-- following: string (nullable = true)\n |    |-- follow_request_sent: string (nullable = true)\n |    |-- notifications: string (nullable = true)\n |-- geo: string (nullable = true)\n |-- coordinates: string (nullable = true)\n |-- place: string (nullable = true)\n |-- contributors: string (nullable = true)\n |-- is_quote_status: boolean (nullable = true)\n |-- retweet_count: long (nullable = true)\n |-- favorite_count: long (nullable = true)\n |-- entities: struct (nullable = true)\n |    |-- hashtags: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- text: string (nullable = true)\n |    |    |    |-- indices: array (nullable = true)\n |    |    |    |    |-- element: long (containsNull = true)\n |    |-- urls: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- url: string (nullable = true)\n |    |    |    |-- expanded_url: string (nullable = true)\n |    |    |    |-- display_url: string (nullable = true)\n |    |    |    |-- indices: array (nullable = true)\n |    |    |    |    |-- element: long (containsNull = true)\n |    |-- user_mentions: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n |    |-- symbols: array (nullable = true)\n |    |    |-- element: string (containsNull = true)\n |-- favorited: boolean (nullable = true)\n |-- retweeted: boolean (nullable = true)\n |-- possibly_sensitive: boolean (nullable = true)\n |-- filter_level: string (nullable = true)\n |-- lang: string (nullable = true)\n |-- timestamp_ms: string (nullable = true)"}], "metadata": {"collapsed": false}}, {"source": "## Read the data and apply the schema\n\nIn the following cell, set `kafkaBrokers` to the broker hosts for your Kafka cluster. The value should be a comma-delimited list of the hosts, similar to the following example:\n\n    wn0-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092,wn1-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092,wn2-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092\n        \nTo find the Kafka brokers information for your Kafka on HDInsight cluster, you can use the Ambari REST API. The following examples demonstrate how to retrieve this information using the the `curl` and `jq` utilities (from Bash) or Windows PowerShell:\n\n* From __Bash__ or other Unix shell:\n\n    ```bash\nCLUSTERNAME='the name of your HDInsight cluster'\nPASSWORD='the password for your cluster login account'\ncurl -u admin:$PASSWORD -G \"https://$CLUSTERNAME.azurehdinsight.net/api/v1/clusters/$CLUSTERNAME/services/KAFKA/components/KAFKA_BROKER\" | jq -r '[\"\\(.host_components[].HostRoles.host_name):9092\"] | join(\",\")'\n    ```\n\n    * From __Azure Powershell__:\n\n    ```powershell\n$creds = Get-Credential -UserName \"admin\" -Message \"Enter the HDInsight login\"\n$clusterName = Read-Host -Prompt \"Enter the Kafka cluster name\"\n$resp = Invoke-WebRequest -Uri \"https://$clusterName.azurehdinsight.net/api/v1/clusters/$clusterName/services/KAFKA/components/KAFKA_BROKER\" `\n    -Credential $creds\n$respObj = ConvertFrom-Json $resp.Content\n$brokerHosts = $respObj.host_components.HostRoles.host_name\n($brokerHosts -join \":9092,\") + \":9092\"\n    ```\n\nWhen you run the next cell, it starts processing data from Kafka from the beginning of the topic. The results are written to the console (displayed as cell output) once the stream ends.\n\nThe output of the stream should appear similar to the following text:\n\n```\n+------------------+---------------+--------------------+\n|                id|           name|                text|\n+------------------+---------------+--------------------+\n|876795956712353792|Alexey Kuritsyn|RT @SnoopyG7: One...|\n|876795954329989120|       amber \u2600\ufe0e|Stained my shirt ...|\n|876795955538006016|        Omalley|RT @kentkristense...|\n|876795954229374976|     \u30aa\u30bf\u30af\u6587\u5316\u306f\u65e5\u672c\u6587\u5316|\u300c\u304a\u3001ARK\u304csteam\u3067980\u5186...|\n|876795957559443457|  Simon Carless|Oo, Nex Machina (...|\n|876795956687130624| Common Grounds|Coffee - it's wha...|\n|876795953264697344|    Scott Crisp|RT @saiyanisland:...|\n+------------------+---------------+--------------------+\n```", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "// kafkaBrokers should contain a comma-delimited list of brokers. For example:\n// kafkaBrokers = \"wn0-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092,wn1-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092,wn2-kafka.liftazhqudlunpo4tkvapo234g.dx.internal.cloudapp.net:9092\"\nval kafkaBrokers=\"your Kafka broker hosts\"\n\n// Read from the Kafka stream source\nval kafka = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", kafkaBrokers).option(\"subscribe\", \"tweets\").option(\"startingOffsets\",\"earliest\").load()\n\n/* Select the following columns from the Kafka data:\n   * value - the JSON data for a tweet\n   Use from_json to apply the schema and store the schematized data in the 'tweet' column\n*/\nval tweetData=kafka.select(\n    from_json(col(\"value\").cast(\"string\"), schema) as \"tweet\")\n\n// There's a lot of data in the Twitter JSON object. Just grab the tweet ID, user name, and text\nval tweetText=tweetData.select(\"tweet.id\",\n                               \"tweet.user.name\",\n                               \"tweet.text\")\n\n// Start writing the stream to the console. Use a timeout so that control is returned to the notebook.\ntweetText.writeStream.format(\"console\").start.awaitTermination(30000)", "outputs": [], "metadata": {"collapsed": false}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}, "anaconda-cloud": {}}}